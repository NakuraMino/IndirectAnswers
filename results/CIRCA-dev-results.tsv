model	accuracy	0	1	2	3	4	5	6	7	8
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_q_e3_lr2e-5_b32	0.737233732127225	0.817286304416905	0.763956043956044	0.8829891838741395	0.4235294117647059	0.8205128205128206	0.0598425196850393	0.4325581395348837	0.2184300341296928	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_a_e3_lr2e-5_b32	0.747446746425445	0.8282405918301704	0.7710694415825263	0.8738049713193117	0.3448275862068965	0.7999999999999999	0.0406091370558375	0.4371584699453552	0.0680851063829787	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_qa_e3_lr3e-5_b32	0.7487598482637876	0.8297274979355905	0.7753833402403647	0.9036885245901638	0.4403669724770642	0.8348623853211009	0.0962406015037594	0.4680851063829787	0.1928571428571428	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_q_e3_lr3e-5_b32	0.8288590604026845	0.8642078792958926	0.8184049079754603	0.8897795591182365	0.3436426116838488	0.8266666666666667	0.0			
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_a_e3_lr2e-5_b32	0.8272541581558214	0.8594507269789985	0.8211490742508113	0.9044193216855088	0.343042071197411	0.8722466960352423	0.0132450331125827			
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_qa_e3_lr3e-5_b32	0.8376130726583018	0.8678592036930178	0.836208567551851	0.8929292929292929	0.29770992366412213	0.8636363636363635	0.0			
