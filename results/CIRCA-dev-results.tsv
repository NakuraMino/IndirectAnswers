model	accuracy	0	1	2	3	4	5	6	7	8	Yes	No	C.yes	Mid	Other	P.yes	P.no	Unsure
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_q_e3_lr2e-5_b32	0.737233732127225	0.817286304416905	0.763956043956044	0.8829891838741395	0.4235294117647059	0.8205128205128206	0.0598425196850393	0.4325581395348837	0.2184300341296928									
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_a_e3_lr2e-5_b32	0.747446746425445	0.8282405918301704	0.7710694415825263	0.8738049713193117	0.3448275862068965	0.7999999999999999	0.0406091370558375	0.4371584699453552	0.0680851063829787									
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_qa_e3_lr3e-5_b32	0.7487598482637876	0.8297274979355905	0.7753833402403647	0.9036885245901638	0.4403669724770642	0.8348623853211009	0.0962406015037594	0.4680851063829787	0.1928571428571428									
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_q_e3_lr3e-5_b32	0.8288590604026845	0.8642078792958926	0.8184049079754603	0.8897795591182365	0.3436426116838488	0.8266666666666667	0.0											
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_a_e3_lr2e-5_b32	0.8272541581558214	0.8594507269789985	0.8211490742508113	0.9044193216855088	0.343042071197411	0.8722466960352423	0.0132450331125827											
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_qa_e3_lr3e-5_b32	0.8376130726583018	0.8678592036930178	0.836208567551851	0.8929292929292929	0.2977099236641221	0.8636363636363635	0.0											
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1813539538955354										0.0027063599458728	0.3350013900472616	0.0293229840448469	0.0	0.0	0.0	0.0	0.0
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2243945141523198										0.002367564368156259	0.3960918933192501	0.029322984044846918	0.0	0.0	0.0		
