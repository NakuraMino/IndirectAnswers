model	accuracy	0	1	2	3	4	5	6	7	8	Yes	No	C.yes	Mid	Other	P.yes	P.no	Unsure
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_q_e3_lr2e-5_b32	0.737233732127225	0.817286304416905	0.763956043956044	0.8829891838741395	0.4235294117647059	0.8205128205128206	0.0598425196850393	0.4325581395348837	0.2184300341296928									
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_a_e3_lr2e-5_b32	0.747446746425445	0.8282405918301704	0.7710694415825263	0.8738049713193117	0.3448275862068965	0.7999999999999999	0.0406091370558375	0.4371584699453552	0.0680851063829787									
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_qa_e3_lr3e-5_b32	0.7487598482637876	0.8297274979355905	0.7753833402403647	0.9036885245901638	0.4403669724770642	0.8348623853211009	0.0962406015037594	0.4680851063829787	0.1928571428571428									
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_q_e3_lr3e-5_b32	0.8288590604026845	0.8642078792958926	0.8184049079754603	0.8897795591182365	0.3436426116838488	0.8266666666666667	0.0											
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_a_e3_lr2e-5_b32	0.8272541581558214	0.8594507269789985	0.8211490742508113	0.9044193216855088	0.343042071197411	0.8722466960352423	0.0132450331125827											
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_qa_e3_lr3e-5_b32	0.8376130726583018	0.8678592036930178	0.836208567551851	0.8929292929292929	0.2977099236641221	0.8636363636363635	0.0											
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1813539538955354										0.0027063599458728	0.3350013900472616	0.0293229840448469	0.0	0.0	0.0	0.0	0.0
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2243945141523198										0.0023675643681562	0.3960918933192501	0.0293229840448469	0.0	0.0	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s0_e3_lr5e-5_b32	0.87268593699253										0.9027823240589198	0.8831498729889924	0.8691588785046729	0.440251572327044	0.9148936170212766	0.0333333333333333		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s1_e3_lr5e-5_b32	0.8602704443013522										0.8942558746736293	0.8673805601317957	0.8640776699029127	0.336	0.8771929824561403	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s2_e3_lr5e-5_b32	0.8709782255443614										0.8960055096418732	0.8863543788187372	0.8947368421052632	0.4055944055944055	0.845360824742268	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s3_e3_lr5e-5_b32	0.8614086335605323										0.8903225806451612	0.8783333333333334	0.8762677484787019	0.288135593220339	0.896	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s4_e3_lr5e-5_b32	0.8698186528497409										0.8982456140350877	0.8854351687388987	0.852589641434263	0.417910447761194	0.8387096774193548	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s5_e3_lr5e-5_b32	0.8699318845280571										0.8974778905994104	0.8818831441782261	0.8733031674208145	0.4032258064516129	0.8181818181818182	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s6_e3_lr5e-5_b32	0.8661903215329653										0.8922651933701657	0.8832571665974241	0.8725314183123878	0.3302752293577981	0.8360655737704918	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s7_e3_lr5e-5_b32	0.8587203637544657										0.894823606989779	0.8669527896995709	0.8541666666666667	0.4217687074829932	0.8988764044943819	0.0253164556962025		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s8_e3_lr5e-5_b32	0.8682673588578845										0.8942924687605539	0.8766572920851747	0.9082774049217002	0.3157894736842105	0.860215053763441	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_unmatched_relaxed_s9_e3_lr5e-5_b32	0.8638421733505821										0.89157413455258	0.8728918140682845	0.8868360277136259	0.3114754098360656	0.8607594936708862	0.0		
