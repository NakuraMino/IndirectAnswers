model	accuracy	Yes	No	C.yes	Mid	Other	P.yes	P.no	Unsure	8
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_q_e3_lr2e-5_b32	0.727020717829005	0.8105500160823416	0.7549040741539126	0.8492610837438422	0.3474178403755868	0.8619246861924685	0.054140127388535	0.4131455399061033	0.2181818181818181	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_a_e3_lr2e-5_b32	0.7350452290633207	0.8133159268929504	0.7697288547146903	0.843444227005871	0.2193548387096774	0.8333333333333334	0.0412371134020618	0.3978201634877384	0.0808823529411764	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_qa_e3_lr3e-5_b32	0.7404435366209513	0.8230925050641459	0.7740249296340973	0.8586278586278586	0.3756345177664975	0.8389830508474576	0.0934579439252336	0.4521739130434782	0.1853035143769968	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_q_e3_lr3e-5_b32	0.8262328567259994	0.8580387685290765	0.8226698262243286	0.8637739656912209	0.3065134099616858	0.8793103448275863	0.0			
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_a_e3_lr2e-5_b32	0.8253574555004377	0.8550052371689361	0.8252032520325203	0.8674948240165632	0.3320754716981132	0.8851063829787233	0.0			
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_qa_e3_lr3e-5_b32	0.8272541581558214	0.8575182481751825	0.827573110520319	0.8653648509763617	0.2633744855967078	0.8706896551724139	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1917128683980157	0.0048577376821651	0.3477539737387699	0.0420600858369098	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.23840093376130728	0.00546448087431694	0.4119722912037642	0.042060085836909865	0.0	0.0	0.0			
