model	accuracy	Yes	No	C.yes	Mid	Other	P.yes	P.no	Unsure	8
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_q_e3_lr2e-5_b32	0.4852640793697111	0.6043521266073195	0.4158628081457663	0.0	0.0	0.8974358974358974	0.003731343283582	0.0	0.0	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_q_e3_lr3e-5_b32	0.5554420776189086	0.6163737676810973	0.5479936362029345	0.0	0.0	0.8918918918918919	0.0127388535031847			
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_a_e3_lr2e-5_b32	0.6927341698278378	0.7816238634550964	0.7240802675585285	0.8338249754178957	0.1805555555555555	0.0	0.0973574408901251	0.3958333333333333	0.1258741258741259	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_a_e3_lr2e-5_b32	0.7811496936095711	0.8193115269247251	0.7796996768675156	0.8505516549648946	0.11	0.0	0.0			
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_strict_qa_e3_lr3e-5_b32	0.7404435366209513	0.8230925050641459	0.7740249296340973	0.8586278586278586	0.3756345177664975	0.8389830508474576	0.0934579439252336	0.4521739130434782	0.1853035143769968	
/home/azureuser/IndirectAnswers/models/CIRCA_BERT_matched_relaxed_qa_e3_lr3e-5_b32	0.8272541581558214	0.8575182481751825	0.827573110520319	0.8653648509763617	0.26337448559670784	0.8706896551724139	0.0			
