model	accuracy	Yes	No	C.yes	Mid	Other	P.yes	P.no	Unsure	8
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2503584743332377	0.0010887316276537	0.4313529705441837	0.0170757737459978	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2302180685358255	0.0026281208935611	0.3935413245758073	0.0345821325648415	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.218	0.0010615711252653	0.3834853090172239	0.0114155251141552	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2291486291486291	0.0036231884057971	0.3817899637868597	0.0837282780410742	0.0	0.0				
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1536419935122382	0.0024676125848241	0.3365870077415012	0.0195372750642673	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2316400580551524	0.0027322404371584	0.3903441191576784	0.0534521158129176	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2753664846220178	0.0073529411764705	0.4538296349319971	0.0	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2497846683893195	0.0	0.4098922624877571	0.058303886925795	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2048088064889918	0.0048899755501222	0.3702687877125617	0.0396881644223954	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2479141835518474	0.020935960591133	0.4268817204301076	0.0382165605095541	0.0	0.0	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2010324060797247	0.0012033694344163	0.3640189374013677	0.0170757737459978	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1813084112149532	0.0014825796886582	0.3244956772334293	0.0345821325648415	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1691428571428571	0.0012820512820512	0.3153928955866523	0.0114155251141552	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1852813852813852	0.0027586206896551	0.3200654307524536	0.0837282780410742	0.0	0.0	0.0	0.0		
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1312297257446181	0.0026899798251513	0.2983814215341309	0.0195372750642673	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1756168359941944	0.0031771247021445	0.3134328358208955	0.0534521158129176	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2198907732106927	0.0078688524590163	0.3817907444668008	0.0	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2035601492965834	0.0	0.3496250323247995	0.058303886925795	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.1645422943221321	0.0054794520547945	0.3103647944412276	0.0396881644223954	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_BERT_e3_lr2e-5_b16	0.2115613825983313	0.0230352303523035	0.3772102161100196	0.0382165605095541	0.0	0.0	0.0	0.0	0.0	
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_matched_relaxed_e3_lr5e-5_b32	0.8383425736796032	0.8683589138134592	0.8432572806529401	0.868041237113402	0.184331797235023	0.8571428571428571	0.0			
/home/azureuser/IndirectAnswers/models/MNLI_CIRCA_BERT_matched_strict_e3_lr2e-5_b32	0.7601400641960899	0.8469098783941363	0.7950060410793395	0.8746177370030581	0.29670329670329676	0.860655737704918	0.06885758998435056	0.4396782841823056	0.18125	
